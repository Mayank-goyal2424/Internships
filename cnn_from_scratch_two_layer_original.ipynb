{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "\n",
    "class Conv3x3:\n",
    "    \n",
    "    def __init__(self, num_filters,f,n_c):\n",
    "        self.num_filters = num_filters\n",
    "        self.n_c = n_c\n",
    "        self.f = f\n",
    "        self.filters = np.random.normal(loc=0, scale=np.sqrt(1./(self.n_c*self.f*self.f)), size=(num_filters,self.n_c, self.f, self.f))\n",
    "        self.t_f = 0\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \n",
    "        u = time.time()\n",
    "        \n",
    "        self.last_input = input\n",
    "    \n",
    "        h, w , n_c = input.shape\n",
    "        \n",
    "        \n",
    "        output = np.zeros((h - self.f+1, w - self.f+1, self.num_filters),dtype=np.float64)\n",
    "    \n",
    "        for i in range(h-self.f+1):\n",
    "            for j in range(w-self.f+1):\n",
    "                for k in range(self.num_filters):\n",
    "                    for n in range(self.n_c):\n",
    "                        #print(\"n\",n)\n",
    "                        imr = input[i:i+self.f,j:j+self.f,n]\n",
    "                        for p in range(self.f):\n",
    "                            for q in range(self.f):\n",
    "                                output[i, j , k] += np.sum( imr[p,q] * self.filters[k,n,p,q])\n",
    "                            \n",
    "                    output[i,j,k] = np.maximum(0,output[i,j,k])\n",
    "                    \n",
    "        self.last_output = output\n",
    "\n",
    "        v =  time.time()\n",
    "        \n",
    "        self.t_f += v-u\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def backprop(self, d_L_d_out, learn_rate):\n",
    "        \n",
    "        d_L_d_out[self.last_output<0] = 0\n",
    "        \n",
    "        d_L_d_filters = np.zeros(self.filters.shape,dtype=np.float64)\n",
    "    \n",
    "        h,w,c = self.last_input.shape\n",
    "        d_L_d_i = np.zeros((h,w,c))\n",
    "        for i in range(h-self.f+1):\n",
    "            for j in range(w-self.f+1):\n",
    "                  for f in range(self.num_filters):\n",
    "                        for n in range(self.n_c):\n",
    "                            d_L_d_filters[f,n,:,:] += d_L_d_out[i, j, f] * self.last_input[i:i+self.f,j:j+self.f,n]\n",
    "                            d_L_d_i[i:i+self.f,j:j+self.f,n] += d_L_d_out[i, j, f] * self.filters[f,n,:,:]\n",
    "                            \n",
    "        self.filters -= learn_rate * d_L_d_filters\n",
    "\n",
    "        return d_L_d_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class MaxPool2:\n",
    "    \n",
    "    def iterate_regions(self, image):\n",
    "        h, w, _ = image.shape\n",
    "        new_h = h // 2\n",
    "        new_w = w // 2\n",
    "    \n",
    "        for i in range(new_h):\n",
    "            for j in range(new_w):\n",
    "                im_region = image[(i * 2):(i * 2 + 2), (j * 2):(j * 2 + 2)]\n",
    "                yield im_region, i, j\n",
    "    \n",
    "    def forward(self, input):\n",
    "    \n",
    "        self.last_input = input\n",
    "\n",
    "        h, w, num_filters = input.shape\n",
    "        output = np.zeros((h // 2, w // 2, num_filters))\n",
    "\n",
    "        for im_region, i, j in self.iterate_regions(input):\n",
    "            output[i, j] = np.amax(im_region, axis=(0, 1))\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backprop(self, d_L_d_out):\n",
    "       \n",
    "        d_L_d_input = np.zeros(self.last_input.shape)\n",
    "\n",
    "        for im_region, i, j in self.iterate_regions(self.last_input):\n",
    "            h, w, f = im_region.shape\n",
    "            amax = np.amax(im_region, axis=(0, 1))\n",
    "\n",
    "            for i2 in range(h):\n",
    "                for j2 in range(w):\n",
    "                      for f2 in range(f):\n",
    "                        # If this pixel was the max value, copy the gradient to it.\n",
    "                            if im_region[i2, j2, f2] == amax[f2]:\n",
    "                                  d_L_d_input[i * 2 + i2, j * 2 + j2, f2] = d_L_d_out[i, j, f2]\n",
    "\n",
    "        return d_L_d_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "class fc_relu:\n",
    "\n",
    "    def __init__(self, input_len, nodes):\n",
    "        self.weights = np.random.randn(input_len, nodes)*np.sqrt(2/nodes,dtype=np.float64)\n",
    "        self.weights[self.weights<-1] = -1\n",
    "        self.weights[self.weights>1] = 1\n",
    "        self.biases = np.zeros(nodes,dtype=np.float64)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \n",
    "        self.last_input_shape = input.shape\n",
    "\n",
    "        input = input.flatten()\n",
    "        self.last_input = input\n",
    "\n",
    "        input_len, nodes = self.weights.shape\n",
    "\n",
    "        totals = np.dot(input, self.weights) + self.biases\n",
    "        self.last_totals = totals\n",
    "\n",
    "        \n",
    "        return totals\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "    def backprop(self, d_L_d_out, learn_rate):\n",
    "        \n",
    "        d_L_d_t = deepcopy(d_L_d_out)\n",
    "        \n",
    "        d_L_d_t[self.last_totals<0] = 0\n",
    "        \n",
    "        d_t_d_w = self.last_input\n",
    "        d_t_d_b = 1\n",
    "        d_t_d_inputs = self.weights\n",
    "        \n",
    "        d_L_d_w = d_t_d_w[np.newaxis].T @ d_L_d_t[np.newaxis]\n",
    "        d_L_d_b = d_L_d_t * d_t_d_b\n",
    "        d_L_d_inputs = d_t_d_inputs @ d_L_d_t\n",
    "\n",
    "        self.weights -= learn_rate * d_L_d_w\n",
    "        self.biases -= learn_rate * d_L_d_b\n",
    "\n",
    "        return d_L_d_inputs.reshape(self.last_input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Softmax:\n",
    "\n",
    "    def __init__(self, input_len, nodes):\n",
    "        self.weights = np.random.normal(loc=0, scale=np.sqrt(1./(input_len*nodes)), size=(input_len,nodes))\n",
    "        self.biases = np.random.normal(loc=0, scale=np.sqrt(1./(nodes)), size=(nodes))\n",
    "\n",
    "    def forward(self, input):\n",
    "        \n",
    "        \n",
    "        self.last_input_shape = input.shape\n",
    "\n",
    "        input = input.flatten()\n",
    "        \n",
    "        self.last_input = input\n",
    "\n",
    "        input_len, nodes = self.weights.shape[0],self.weights.shape[1]\n",
    "\n",
    "        totals = np.dot(input, self.weights) + self.biases\n",
    "        \n",
    "        totals -= np.max(totals)\n",
    "        \n",
    "        self.last_totals = totals\n",
    "        \n",
    "        exp = np.exp(totals,dtype=np.float64)\n",
    "        \n",
    "        return exp / np.sum(exp, axis=0)\n",
    "\n",
    "    def backprop(self, d_L_d_out, learn_rate):\n",
    "        \n",
    "        for i, gradient in enumerate(d_L_d_out):\n",
    "            if gradient == 0:\n",
    "                continue\n",
    "\n",
    "            t_exp = np.exp(self.last_totals)\n",
    "\n",
    "            S = np.sum(t_exp)\n",
    "\n",
    "            d_out_d_t = -t_exp[i] * t_exp / (S ** 2)\n",
    "            d_out_d_t[i] = t_exp[i] * (S - t_exp[i]) / (S ** 2)\n",
    "            \n",
    "            d_t_d_w = self.last_input\n",
    "            d_t_d_b = 1\n",
    "            d_t_d_inputs = self.weights\n",
    "\n",
    "            d_L_d_t = gradient * d_out_d_t\n",
    "\n",
    "            d_L_d_w = d_t_d_w[np.newaxis].T @ d_L_d_t[np.newaxis]\n",
    "            d_L_d_b = d_L_d_t * d_t_d_b\n",
    "            d_L_d_inputs = d_t_d_inputs @ d_L_d_t\n",
    "\n",
    "            self.weights -= learn_rate * d_L_d_w\n",
    "            self.biases -= learn_rate * d_L_d_b\n",
    "\n",
    "            return d_L_d_inputs.reshape(self.last_input_shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import MNIST\n",
    "\n",
    "mndata = MNIST(r'C:\\Users\\krish\\OneDrive\\Documents\\krishna\\sem6\\DL\\mnist')\n",
    "\n",
    "mndata.gz = True\n",
    "\n",
    "train_images = np.zeros([400,28,28,1])\n",
    "test_images = np.zeros([100,28,28,1])\n",
    "\n",
    "\n",
    "images_tr,train_labels = mndata.load_training()\n",
    "images_tr = np.array(images_tr[:400])\n",
    "train_labels = np.array(train_labels[:400])\n",
    "    \n",
    "\n",
    "images_ts1,test_labels = mndata.load_testing()\n",
    "images_ts = np.array(images_ts1[:100])\n",
    "test_labels = np.array(test_labels[0:100])\n",
    "\n",
    "\n",
    "for i in range(400):\n",
    "    train_images[i] = images_tr[i].reshape(28,28,1) \n",
    "    \n",
    "for i in range(100):    \n",
    "    test_images[i] = images_ts[i].reshape(28,28,1)\n",
    "    \n",
    "#print(train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Epoch 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training_data: 100%|█████████████████████████████████████████████████████████████████| 400/400 [04:02<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after epoch1 loss is 2.242060804192134 accuracy is 0.1675\n",
      "\n",
      "\n",
      "--- Epoch 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training_data: 100%|█████████████████████████████████████████████████████████████████| 400/400 [04:09<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after epoch2 loss is 1.1644775295468663 accuracy is 0.6525\n",
      "\n",
      "\n",
      "--- Epoch 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training_data: 100%|█████████████████████████████████████████████████████████████████| 400/400 [03:53<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after epoch3 loss is 0.6700316495859814 accuracy is 0.785\n",
      "Testing on test data set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_data: 100%|█████████████████████████████████████████████████████████████████████| 100/100 [00:53<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on test dataset: 0.7951450118170683\n",
      "Accuracy on test dataset: 0.77\n",
      "\n",
      "\n",
      "total time taken is  726.9290916919708\n",
      "total time taken for conv forward prop is  503.93260526657104\n"
     ]
    }
   ],
   "source": [
    "import mnist\n",
    "import numpy as np\n",
    "import tqdm as tqdm\n",
    "\n",
    "conv1 = Conv3x3(8,3,1)\n",
    "pool1 = MaxPool2()\n",
    "\n",
    "conv2 = Conv3x3(8,3,1)\n",
    "pool2 = MaxPool2()\n",
    "\n",
    "#fc_r = fc_relu(200,84)\n",
    "\n",
    "softmax = Softmax(200, 10) \n",
    "\n",
    "def forward(image, label): \n",
    "    \n",
    "    out = conv1.forward((image/255) )\n",
    "    out = pool1.forward(out)\n",
    "    out = conv2.forward(out)\n",
    "    out = pool2.forward(out)\n",
    "    #out = fc_r.forward(out)\n",
    "    out = softmax.forward(out)\n",
    "    \n",
    "    if out[label] == 0:\n",
    "        out[label] = sys.float_info.min\n",
    "    \n",
    "    \n",
    "    loss = -np.log(out[label])\n",
    "    acc = 1 if np.argmax(out) == label else 0\n",
    "\n",
    "    return out, loss, acc\n",
    "\n",
    "def train(im, label, lr=.005):\n",
    "   \n",
    "    out, loss, acc = forward(im, label)\n",
    "\n",
    "    gradient = np.zeros(10)\n",
    "    if out[label] == 0:\n",
    "        out[label] = sys.float_info.min\n",
    "    gradient[label] = -1 / out[label]\n",
    "\n",
    "    gradient = softmax.backprop(gradient, lr)\n",
    "    #gradient = fc_r.backprop(gradient, lr)\n",
    "    gradient = pool2.backprop(gradient)\n",
    "    gradient = conv2.backprop(gradient, lr)\n",
    "    gradient = pool1.backprop(gradient)\n",
    "    gradient = conv1.backprop(gradient, lr)\n",
    "    \n",
    "    return loss, acc\n",
    "\n",
    "t1 = time.time()\n",
    "for epoch in range(3):\n",
    "#     break\n",
    "    print('\\n')\n",
    "    print('--- Epoch %d ---' % (epoch + 1))\n",
    "\n",
    "    permutation = np.random.permutation(len(train_images))\n",
    "    train_images = train_images[permutation]\n",
    "    train_labels = train_labels[permutation]\n",
    "    \n",
    "    loss = 0\n",
    "    num_correct = 0\n",
    "    outer = tqdm.tqdm(total=len(train_images), desc='training_data', position=0)\n",
    "    \n",
    "    for i, (im, label) in enumerate(zip(train_images, train_labels)):\n",
    "        outer.update(1)\n",
    "        l, acc = train(im, label)\n",
    "        loss += l\n",
    "        num_correct += acc\n",
    "        \n",
    "        \n",
    "        \n",
    "    print('after epoch' + str(epoch+1) + ' loss is ' + str(loss/len(train_images)) + ' accuracy is ' + str(num_correct/len(train_images)))\n",
    "    \n",
    "    \n",
    "t2 = time.time()\n",
    "\n",
    "total_time = t2-t1\n",
    "\n",
    "total_time_conv = conv1.t_f \n",
    "        \n",
    "        \n",
    "print('Testing on test data set')\n",
    "loss = 0\n",
    "num_correct = 0\n",
    "\n",
    "test = tqdm.tqdm(total=len(test_images), desc='test_data', position=0)\n",
    "    \n",
    "for im, label in zip(test_images, test_labels):\n",
    "    test.update(1)\n",
    "    _, l, acc = forward(im, label)\n",
    "    loss += l\n",
    "    num_correct += acc\n",
    "\n",
    "\n",
    "\n",
    "num_tests = len(test_images)\n",
    "print('Loss on test dataset:', loss / num_tests)\n",
    "print('Accuracy on test dataset:', num_correct / num_tests)\n",
    "print('\\n')\n",
    "print('total time taken is ',total_time)\n",
    "print('total time taken for conv forward prop is ',total_time_conv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test cases: \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "input image :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " predicted Output2\n",
      "\n",
      "\n",
      "input image :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " predicted Output5\n",
      "\n",
      "\n",
      "input image :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " predicted Output8\n",
      "\n",
      "\n",
      "input image :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " predicted Output6\n",
      "\n",
      "\n",
      "input image :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " predicted Output4\n",
      "\n",
      "\n",
      "input image :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " predicted Output5\n",
      "\n",
      "\n",
      "input image :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " predicted Output0\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow, show\n",
    "\n",
    "def predict_out(image):\n",
    "\n",
    "    out = conv1.forward((image / 255) - 0.5)\n",
    "    out = pool1.forward(out)\n",
    "    out = Softmax(1352,10).forward(out)\n",
    "    \n",
    "    return np.argmax(out)\n",
    "\n",
    "\n",
    "\n",
    "print(\"test cases: \\n\\n \")\n",
    "\n",
    "for j in range(7):\n",
    "    rand = randint(1000,2000)\n",
    "    print(\"\\n\\ninput image :\")\n",
    "    test_img = np.array(images_ts1[rand]).reshape(28,28)\n",
    "    imshow(test_img)\n",
    "    show()\n",
    "    \n",
    "    print(\" predicted Output\" , end = \"\")\n",
    "    print(predict_out(test_img.reshape(28,28,1)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-7b0e9b52719b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-8-7b0e9b52719b>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    Loss on test dataset: 0.9290618471892992\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Loss on test dataset: 0.9290618471892992\n",
    "Accuracy on test dataset: 0.74\n",
    "\n",
    "\n",
    "total time taken is  1669.1526427268982\n",
    "total time taken for conv forward prop is  599.6809167861938"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy on test dataset: 0.77\n",
    "\n",
    "\n",
    "total time taken is  726.9290916919708\n",
    "total time taken for conv forward prop is  503.93260526657104"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
